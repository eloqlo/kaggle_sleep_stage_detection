{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Credits:\n\n- https://www.kaggle.com/code/itsuki9180/detect-sleep-states-dataprepare  \n- https://www.kaggle.com/code/werus23/sleep-critical-point-prepare-data\n\nGO TO:\nData Preparation - this\nTRAIN - https://www.kaggle.com/code/jhjh97/transformer-train\nINFERENCE - Not Yet\n\nThis does:\n- Save preprocessed gaussian outputs according to following parameters `N_DAYS_PER_SAMPLE`, `SEPERATE_FEATURES`.\n- `N_DAYS_PER_SAMPLE`(int) is how many days you like to windowing for model.\n- `SEPERATE_FEATURES`(bool) whether you split your data for seperated model.\n- `SIGMA` for gaussian sigma value(std). more smaller SIGMA is, more sharper distribution gets.","metadata":{}},{"cell_type":"markdown","source":"## Ver1.1","metadata":{}},{"cell_type":"markdown","source":"- Split hard sample and easy samples\n- enmo + anglez","metadata":{}},{"cell_type":"code","source":"N_DAYS_PER_SAMPLE = 3\nFIT_INTO_1DAY = True\nSEPERATE_FEATURES = True  # Not Used\n\nSIGMA = 720 # target gaussian parameter, 12 * 60","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T03:09:28.747934Z","iopub.execute_input":"2023-11-18T03:09:28.748412Z","iopub.status.idle":"2023-11-18T03:09:28.754450Z","shell.execute_reply.started":"2023-11-18T03:09:28.748374Z","shell.execute_reply":"2023-11-18T03:09:28.752891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport time\nimport json\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport os\nfrom os.path import join, exists\nimport joblib\nimport random\nimport math\nfrom tqdm.auto import tqdm \nimport shutil\n\nfrom scipy.interpolate import interp1d\n\nfrom math import pi, sqrt, exp\nimport sklearn,sklearn.model_selection\nimport torch\nfrom torch import nn,Tensor\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom sklearn.metrics import average_precision_score\nfrom timm.scheduler import CosineLRScheduler\nplt.style.use(\"ggplot\")\n\nfrom pyarrow.parquet import ParquetFile\nimport pyarrow as pa \nimport ctypes","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:09:29.195134Z","iopub.execute_input":"2023-11-18T03:09:29.195600Z","iopub.status.idle":"2023-11-18T03:09:29.208873Z","shell.execute_reply.started":"2023-11-18T03:09:29.195565Z","shell.execute_reply":"2023-11-18T03:09:29.207372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_dir = \"train_data\"\nos.makedirs(out_dir, exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:09:34.053488Z","iopub.execute_input":"2023-11-18T03:09:34.053986Z","iopub.status.idle":"2023-11-18T03:09:34.059877Z","shell.execute_reply.started":"2023-11-18T03:09:34.053948Z","shell.execute_reply":"2023-11-18T03:09:34.058826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PATHS:\n    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n    # CSV FILES : \n    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n    # PARQUET FILES:\n    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n    SAVE_DIR = out_dir","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:09:34.239274Z","iopub.execute_input":"2023-11-18T03:09:34.240324Z","iopub.status.idle":"2023-11-18T03:09:34.245749Z","shell.execute_reply.started":"2023-11-18T03:09:34.240283Z","shell.execute_reply":"2023-11-18T03:09:34.244264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_events(data_path, save_dir):\n    \"\"\" events.csv \"\"\"\n    events = pd.read_csv(data_path)\n    if not exists(join(save_dir, 'id_map.parquet')):\n        id_map = pd.DataFrame({\"series_id\": events.series_id.unique(),\n                                \"id_index\": [i for i in range(len(events.series_id.unique()))]})\n        id_map.id_index = id_map.id_index.astype(np.uint16)\n        id_map.to_parquet(os.path.join(save_dir,\"id_map.parquet\"), index=False)\n    id_map = pd.read_parquet(os.path.join(save_dir,\"id_map.parquet\"))\n    events.dropna(subset=['step'], inplace=True)\n    # reduce memory size + event re-label\n    events = events.merge(right=id_map, on=\"series_id\").drop(columns=\"series_id\")\n    events.step = events.step.astype(np.uint32)\n    events.night = events.night.astype(np.uint16)\n#     events.to_csv(os.path.join(save_dir,'preprocessed_events.csv'), index=False)\n    \n    return events","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:09:34.427842Z","iopub.execute_input":"2023-11-18T03:09:34.428845Z","iopub.status.idle":"2023-11-18T03:09:34.440372Z","shell.execute_reply.started":"2023-11-18T03:09:34.428785Z","shell.execute_reply":"2023-11-18T03:09:34.438172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_series(data_path, save_dir):\n    \"\"\" train_series.parquet \"\"\"\n    # reduce memory\n    series = pd.read_parquet(data_path)\n    if not exists(join(save_dir, 'id_map.parquet')):\n        id_map = pd.DataFrame({\"series_id\": series.series_id.unique(),\n                                \"id_index\": [i for i in range(len(series.series_id.unique()))]})\n        id_map.id_index = id_map.id_index.astype(np.uint16)\n        id_map.to_parquet(os.path.join(save_dir,\"id_map.parquet\"), index=False)\n    \n    id_map = pd.read_parquet(os.path.join(save_dir,\"id_map.parquet\"))\n    series = series.merge(right=id_map, on='series_id').drop(columns='series_id').reset_index()\n    series.step = series.step.astype(np.uint32)\n\n    # normalize enmo and anglez\n    mean_enmo = series['enmo'].mean()\n    std_enmo = series['enmo'].std()\n    series.enmo = (series['enmo'] - mean_enmo)/std_enmo\n    mean_anglez = series['anglez'].mean()\n    std_anglez = series['anglez'].std()\n    series.anglez = (series['anglez'] - mean_anglez)/std_anglez\n    \n    series = series.drop(columns='index')\n#     series.to_parquet(os.path.join(save_dir,'preprocessed_series.parquet'))\n    \n    return series","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:09:34.579716Z","iopub.execute_input":"2023-11-18T03:09:34.580109Z","iopub.status.idle":"2023-11-18T03:09:34.592598Z","shell.execute_reply.started":"2023-11-18T03:09:34.580078Z","shell.execute_reply":"2023-11-18T03:09:34.590898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# must process events first.\nevents = preprocess_events(PATHS.TRAIN_EVENTS, PATHS.SAVE_DIR)\nseries = preprocess_series(PATHS.TRAIN_SERIES, PATHS.SAVE_DIR)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:09:34.751951Z","iopub.execute_input":"2023-11-18T03:09:34.752397Z","iopub.status.idle":"2023-11-18T03:11:58.749347Z","shell.execute_reply.started":"2023-11-18T03:09:34.752365Z","shell.execute_reply":"2023-11-18T03:11:58.747798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"converting evetns into gaussian target numpy array.","metadata":{}},{"cell_type":"code","source":"def gauss(n=SIGMA,sigma=SIGMA*0.15):\n    # guassian distribution function\n    r = range(-int(n/2),int(n/2)+1)  # int는 나머지 버림계산\n    return [1 / (sigma * sqrt(2*pi)) * exp(-float(x)**2/(2*sigma**2)) for x in r]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:11:58.751677Z","iopub.execute_input":"2023-11-18T03:11:58.752089Z","iopub.status.idle":"2023-11-18T03:11:58.761044Z","shell.execute_reply.started":"2023-11-18T03:11:58.752054Z","shell.execute_reply":"2023-11-18T03:11:58.759698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pad_amount(series):\n    # For fitting data into 24 hours cycle, get how much series need to be zero_padded for front and end.\n    # 0.4145 secs\n    f_h=series.timestamp.dt.hour[0]\n    f_m=series.timestamp.dt.minute[0]\n    f_s=series.timestamp.dt.second[0]\n    r_h=list(series.timestamp.dt.hour)[-1]\n    r_m=list(series.timestamp.dt.minute)[-1]\n    r_s=list(series.timestamp.dt.second)[-1]\n    \n    # calc how many steps first data is apart from 0:00:00.\n    front = f_s//5 + f_m*12 + f_h*(12*60)\n    if front>0:\n        front -= 1\n    \n    # calc how many steps rear data is apart from 23:59:55\n    max_step = 24*60*12\n    end = max_step - (r_s//5 + r_m*12 + r_h*(12*60))\n    \n    return front, end","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:11:58.763196Z","iopub.execute_input":"2023-11-18T03:11:58.763694Z","iopub.status.idle":"2023-11-18T03:11:58.777399Z","shell.execute_reply.started":"2023-11-18T03:11:58.763646Z","shell.execute_reply":"2023-11-18T03:11:58.776134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New 2","metadata":{}},{"cell_type":"markdown","source":"### can i reduce data size? -> Y\n\n- 어차피 conv 계열만 쓰기에, X 임베딩을 0-24로 맞출 필요가 없음.\n- 하지만, 잠들기 전 후로 데이터에 증거가 많이 남아있을 것 같음. 그래서 (전날 오후 6시 ~ 당일 ~ 다음날 오전 6시)로 시간을 맞춰줄 예정. \n- 24+6+6=36시간 = 25920, /60=432  \n\n#### easy, hard(unlabelded)로 나눠주기\n\n- 일단 easy로 학습시키고 모델이 얼마나 잘 성능 나오는지 보고싶음\n- easy(train,val), mixed(train,val), hard(tarin,val)\n- 기준은 하루동안 label이 없으면 hard example","metadata":{}},{"cell_type":"code","source":"data_counter=0\nenmo_x=[]\nenmo_y=[]\nattach_hours=6\nids = pd.read_parquet(os.path.join(PATHS.SAVE_DIR,\"id_map.parquet\"))\n\nif SEPERATE_FEATURES:\n    os.makedirs(PATHS.SAVE_DIR+'/hard', exist_ok = True)\n    os.makedirs(PATHS.SAVE_DIR+'/fine', exist_ok = True)\n\n# for ids, make \"series + target_gaussian\" vector and store them ids by ids.\nfor cur_id in tqdm(ids.id_index, total=len(ids)):\n    cur_targets = []\n    cur_events = events[events.id_index == cur_id].copy()\n    cur_series = series.loc[(series.id_index == cur_id)].copy().reset_index(drop=True)\n    cur_series['timestamp'] = pd.to_datetime(cur_series.timestamp,format = '%Y-%m-%dT%H:%M:%S%z').astype(\"datetime64[ns, UTC-04:00]\")\n    \n    # calculate how many steps needed to pad for each series\n    front, end = get_pad_amount(cur_series)\n    cur_events.step += front\n    total_len = len(cur_series)+front+end\n    target_gaussian = np.zeros((total_len,2))  # onset:0, wakeup:1\n    for i in range(len(cur_events)):\n        s=cur_events.iloc[i].step\n        gau_st = max(SIGMA//2-s, 0)\n        gau_ed = SIGMA+(SIGMA+1)%2+1 - max(s+SIGMA//2-(len(target_gaussian)-1), 0)\n        tar_st = max(0, s-SIGMA//2)\n        tar_ed = min(len(target_gaussian), s+SIGMA//2+1)\n        if cur_events.iloc[i].event=='onset':\n            target_gaussian[tar_st:tar_ed,0] = gauss()[gau_st:gau_ed]\n        if cur_events.iloc[i].event=='wakeup':\n            target_gaussian[tar_st:tar_ed,1] = gauss()[gau_st:gau_ed]\n\n    # zero padding for series\n    cur_series = cur_series.drop(columns=['id_index','step','timestamp'])\n    zero_pad_front = pd.DataFrame({'anglez':[0 for _ in range(front)], 'enmo':[0 for _ in range(front)]}, dtype=np.float32)\n    zero_pad_end = pd.DataFrame({'anglez':[0 for _ in range(end)], 'enmo':[0 for _ in range(end)]}, dtype=np.float32)\n    cur_series = pd.concat([zero_pad_front, cur_series, zero_pad_end], ignore_index=True)\n    del zero_pad_front, zero_pad_end\n    gc.collect()\n    \n    # normalize target into max value.\n    target_gaussian /= np.max(target_gaussian + 1e-12)\n    \n    # append target onto series,\n    cur_series['onset'] = target_gaussian[:,0]\n    cur_series['wakeup'] = target_gaussian[:,1]\n    \n    # save it into croped size\n    one_day_steps = (24*60*12)\n    cur_series_days = len(cur_series)//one_day_steps\n    for i in range(cur_series_days - N_DAYS_PER_SAMPLE + 1):\n        st = i*one_day_steps\n        ed = (i+N_DAYS_PER_SAMPLE)*one_day_steps\n        st2=(24-attach_hours)*60*12\n        ed2=-(24-attach_hours)*60*12\n        \n        sample = cur_series[st:ed][st2:ed2]\n        if sum(sample['onset'])==0.0 and sum(sample['wakeup'])==0.0:\n            sample.to_csv(f'{PATHS.SAVE_DIR}/hard/id{cur_id}_{data_counter}.csv', index=False)\n        else:\n            # onset, wakeup 하나라도 있으면 fine에 저장\n            sample.to_csv(f'{PATHS.SAVE_DIR}/fine/id{cur_id}_{data_counter}.csv', index=False)\n        data_counter+=1\n    del cur_series, cur_events, target_gaussian, sample\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:11:58.780036Z","iopub.execute_input":"2023-11-18T03:11:58.780885Z","iopub.status.idle":"2023-11-18T03:13:07.811682Z","shell.execute_reply.started":"2023-11-18T03:11:58.780806Z","shell.execute_reply":"2023-11-18T03:13:07.809158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dir move","metadata":{}},{"cell_type":"code","source":"# Zip file. Because amount of data is over 50.\nshutil.move(f'{PATHS.SAVE_DIR}/id_map.parquet', './')\nevents[:3].copy().to_csv('./dummy.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:01:05.184008Z","iopub.execute_input":"2023-11-18T03:01:05.184418Z","iopub.status.idle":"2023-11-18T03:01:05.196136Z","shell.execute_reply.started":"2023-11-18T03:01:05.184384Z","shell.execute_reply":"2023-11-18T03:01:05.194572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('./fine','zip',f'{PATHS.SAVE_DIR}/fine')\nshutil.make_archive('./hard','zip',f'{PATHS.SAVE_DIR}/hard')\nshutil.rmtree(f'./{PATHS.SAVE_DIR}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T03:01:05.198093Z","iopub.execute_input":"2023-11-18T03:01:05.198561Z","iopub.status.idle":"2023-11-18T03:01:06.247581Z","shell.execute_reply.started":"2023-11-18T03:01:05.198524Z","shell.execute_reply":"2023-11-18T03:01:06.246420Z"},"trusted":true},"execution_count":null,"outputs":[]}]}